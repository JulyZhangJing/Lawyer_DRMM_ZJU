#data processing

You should treat your data format as 'sample.txt', formatted as 'label \t query\t document_txt'.In detail, label donotes the relation between query and document, 1 means the query is related to the document, otherwise it does not matter.the words in query and documents are separated by white space.To understand that most models require 'corpus_preprocessed.txt', 'relation_train.txt', 'relation_valid.txt', 'relation_test.txt', 'embed_glove_d50' files,do the following:

1.Generating the files named 'relation_train.txt', 'relation_valid.txt', 'relation_test.txt' and 'corpus.txt' by excuting the file named  'preparation.py' 

## begining of this process
1)create Preparation object.
2)specify the base directory where you want to load the files.
3)call the function 'run_with_one_corpus' of the Preparation object and specify a parameter, which is denotes the raw data.The function of 'run_with_one_corpus' is transfering the format of 'sample.txt' to the format like this 'id words', then outputing the relation files 'rel' between queries and doecuments.
4)save 'corpus.txt' by calling the function 'save_corpus' of Preparation object.
5)shuffle the relationship in the file 'rel', and then cut it into a specified percentage of the file. Detailedly, If you want to adjust output data radio, specify the seond parameter of function 'split_train_valid_test', and which represent the percentage of the training data, valid data, test data, orderly.
6)save relationship file by calling the function 'save_relation' of Preparation object, with specify the path you want to save. 
## ending of this process

 
2.Generating the files named 'corpus_preprocessed.txt' , 'wodr_dict.txt'. And if you need CF,CF,IDF of documents,you can save 'word_stats.txt' by excuting function 'preprocessor.save_words_stats'. Amply, the models in MatchZoo requires that all words must be id instead of string, so you should map the string to id by excuting the function named 'preprocessor.run', then specify it's output name and save it.Generate the files , referencing to the function 'main' of the file 'preprocess.py' 

## begining of this process
1)create Preprocess object, and you can specify the parameter making some constriant like spcify the frequence of words, which is filtered if the words do not in thei frequency band etc.
2)excute the function 'run' of object Preprocess, then get the documents' id and words mapped as id, with your inititialization paramters.
3)save word dict file by excuting function 'save_word_dict' of Preprocess object, and save 'word_stats.txt' by excuting function  'save_words_stats' of Preprocess object too, which contains information like DF,CF,IDF sequentially.
4)then save corpus information whose words has been mapped as id, with specified path by yourself.
## ending of this process

3.Generating the file named 'embed' by excuting the file named 'gen_w2v.py' , whith three parameters 'word_vector', 'word_dict.txt', 'embed', And the first parameter denotes the embedding download from url'http://nlp.stanford.edu/data/glove.840B.300d.zip' or where you want, the second parameter denotes the file mapping string words to words id, the last paramter denotes the output embedding for your own dataset starting with word id and following with embeddings.

## begining of this process
1)lo ad word dict file and word vectors sequentially.
2)get the dimension of embedding you downloaded.
3)get the third parameter where is the path you want to output.
4)write the word embedding in your corpus.
5)randomly generated it, if the words in your corpus not in the embedding file you downloaded. 
## ending of this process